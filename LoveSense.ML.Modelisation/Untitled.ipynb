{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "import pickle \n",
    "\n",
    "#Analytic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ML\n",
    "#ML.Vectorize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#ML.Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "#ML.Reduction\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import KernelPCA\n",
    "#ML.Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#ML.Evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "#Optimisation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#UserModule\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "# @todo = refac later to the right way\n",
    "sys.path.append(str(Path(os.path.dirname(os.path.abspath(__file__))).parent)+'\\\\LoveSence.ML.Communs')\n",
    "import AccessCorpus as corpus\n",
    "import PersistenceProvider as db_provider\n",
    "import CleanningCorpus as cleanning\n",
    "\n",
    "def echantilloner_donnees(corpus):\n",
    "    # Split the data into train & test sets:\n",
    "    X = corpus['clean_message']\n",
    "    y = corpus['alabel']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state = 42)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "def definir_experiences():\n",
    "    #Vectorisation\n",
    "    tfidf = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "    tf = CountVectorizer(stop_words='english')\n",
    "    ngram3 = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "\n",
    "    #Sélection des caracteristiques\n",
    "    ki2 = SelectKBest(chi2)\n",
    "    mic = SelectKBest(mutual_info_classif) \n",
    "\n",
    "    #Réduction des caracteristiques\n",
    "    nmf = NMF() # Factorisation par matrices non-négatives\n",
    "    lsa = TruncatedSVD()# latent semantic analysis\n",
    "    ipca = KernelPCA() # Analyse en composantes principales\n",
    "\n",
    "    #modèle standard\n",
    "    mnb = MultinomialNB() # naive baye\n",
    "    svm = SVC(kernel='linear')  # svm\n",
    "    rf = RandomForestClassifier(n_estimators = 100) # random forest\n",
    "    kn = KNeighborsClassifier(n_neighbors=3) # KNeighbors\n",
    "\n",
    "    #Expériences\n",
    "    return {'vectoriser': [('tf',tf), ('tfidf',tfidf)],\n",
    "            'selectinner': [('mic',mic), ('ki2',ki2)],\n",
    "            'reduire': [('nmf',nmf), ('lsa',lsa)],\n",
    "            'modeliser': [('kn',kn), ('mnb',mnb)]}\n",
    "    #return {'vectoriser': [('tf',tf), ('tfidf',tfidf), ('ngram3',ngram3)],\n",
    "    #        'selectinner': [('mic',mic), ('ki2',ki2)],\n",
    "    #        'reduire': [('nmf',nmf), ('lsa',lsa), ('ipca',ipca)],\n",
    "    #        'modeliser': [('kn',kn), ('mnb',mnb), ('rf',rf), ('svm',svm)]}\n",
    "    #return {'vectoriser': [('tf',tf)],\n",
    "    #        'selectinner': [('ki2',ki2)],\n",
    "    #        'reduire': [('ipca',ipca)],\n",
    "    #        'modeliser': [('svm',svm)]}\n",
    "\n",
    "def conduire_experimentation(donnees_experiences, experiences):  \n",
    "    X_train, X_test = donnees_experiences[0], donnees_experiences[1]\n",
    "    y_train, y_test = donnees_experiences[2], donnees_experiences[3]\n",
    "\n",
    "    vectoriser_methodes = experiences['vectoriser']\n",
    "    selectinner_methodes = experiences['selectinner']\n",
    "    reduire_methodes = experiences['reduire']\n",
    "    modeliser_methodes = experiences['modeliser']\n",
    "\n",
    "    resultats = []\n",
    "\n",
    "    for v in vectoriser_methodes:\n",
    "        for s in selectinner_methodes:\n",
    "            for r in reduire_methodes:\n",
    "                for m in modeliser_methodes:\n",
    "                    resultats.append(conduire_experience(X_train, y_train, X_test, y_test, v, s, r, m))\n",
    "    return resultats\n",
    "\n",
    "def conduire_experience(X_train, y_train, X_test, y_test, vectoriser, selectionner, reduire,  modeliser):\n",
    "    score, n_components, k, t_training, t_test = -1, 0, 0, 0, 0\n",
    "    experience_impossible = False\n",
    "    erreur_experience = ''\n",
    "    matrice_confusion = []\n",
    "    ml_experience, autres_metriques = {}, {}\n",
    "    methods_pickle, model_pickle, matrice_confusion_pickle = None, None, None\n",
    "    code_experience = vectoriser[0] + '_' + selectionner[0] + '_' + reduire[0] + '_' + modeliser[0]\n",
    "    print(str(datetime.now()) + ' Expérience:{0} - {1} {2} {3} {4}'.format(code_experience, vectoriser[0], selectionner[0], reduire[0], modeliser[0]))\n",
    "                    \n",
    "    try:\n",
    "        t0 = time()\n",
    "        model = construire_modele(X_train, y_train, vectoriser[1], selectionner[1], reduire[1], modeliser[1])\n",
    "        t_training = time() - t0\n",
    "    except Exception as e:\n",
    "        erreur_experience = str(e)\n",
    "        experience_impossible = True\n",
    "        pass\n",
    "                    \n",
    "    if (experience_impossible == False):\n",
    "        t0 = time()\n",
    "        metriques_evalusation = evaluer_experience(model,  X_test, y_test)\n",
    "        t_test = time() - t0\n",
    "        score = metriques_evalusation['accuracy_score']\n",
    "        matrice_confusion_pickle = pickle.dumps(metriques_evalusation['confusion_matrix'])\n",
    "        autres_metriques = metriques_evalusation['classification_report']\n",
    "        k = model.best_params_['sel__k']\n",
    "        n_components = model.best_params_['red__n_components']\n",
    "        methods_pickle = pickle.dumps({\n",
    "                'vectorizer' : vectoriser[1],\n",
    "                'selector' : selectionner[1],\n",
    "                'reductor' : reduire[1],\n",
    "                'classifier' : modeliser[1]\n",
    "            })  \n",
    "        model_pickle = pickle.dumps(model)\n",
    "\n",
    "        ml_experience = {'date_experience': datetime.now(), 'type': 'I', 'methods_pickle': methods_pickle, 'code_experience' :code_experience,\n",
    "           'score':score , 'matrice_confusion_pickle': matrice_confusion_pickle, 'autres_metriques' :  autres_metriques,\n",
    "           'n_components': n_components, 'k': k, 'erreur_experience': erreur_experience, 'time_training': t_training , 'time_test' : t_test, 'model_pickle' : model_pickle}\n",
    "        \n",
    "        #mongo_db = db_provider.MongoDB('experiences').ajouter_document(ml_experience)\n",
    "    return ml_experience\n",
    "\n",
    "def construire_modele(X_train, y_train, vectoriser, selectionner, reduire, modeliser):\n",
    "    pipe = Pipeline([('vec', vectoriser),\n",
    "                     ('sel', selectionner),\n",
    "                     ('red', reduire),\n",
    "                     ('mod', modeliser)])\n",
    "     \n",
    "    #param_grid = {\n",
    "    #   'sel__k': [500, 1000, 2500],\n",
    "    #   'red__n_components': [10, 50, 100]}\n",
    "    param_grid = {\n",
    "       'sel__k': [1000],\n",
    "       'red__n_components': [300]}\n",
    "    search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1).fit(X_train, y_train)\n",
    "    return search \n",
    "\n",
    "def evaluer_experience(model, X_test, y_test):\n",
    "    y_predic = model.predict(X_test)\n",
    "    scores_evalusation = {\n",
    "        'confusion_matrix' : confusion_matrix(y_test, y_predic),\n",
    "        'classification_report' : classification_report(y_test, y_predic, output_dict =True),\n",
    "        'accuracy_score' :metrics.accuracy_score(y_test, y_predic)\n",
    "       }\n",
    "\n",
    "    return scores_evalusation\n",
    "\n",
    "def resultats_experience_to_panda(array):\n",
    "    resultats_panda = pd.DataFrame([], columns = ['date_experience', 'type', 'vectoriser' , 'selectinner', 'reduire', 'modeliser','code_experience' ,'score','n_components','k','erreur_experience','time_training', 'time_test'])\n",
    "    resultats_panda.append(array, ignore_index=True)\n",
    "    \n",
    "    return resultats_panda\n",
    "\n",
    "def editier_experimentation(resultats):\n",
    "    result = resultats[resultats.score != -1]\n",
    "    result = result.sort_values(by=['score'])\n",
    "    scores = result['score'].values.tolist()\n",
    "    experiences = result['code_experience'].values.tolist()\n",
    "    fig, ax = plt.subplots()\n",
    "    index = np.arange(len(experiences))\n",
    "    plt.barh(index, scores, color= 'blue', align='center')\n",
    "    ax.set_yticks(index)\n",
    "    ax.set_yticklabels(experiences)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title(\"Score selon l'expérience\")\n",
    "    plt.show()\n",
    "\n",
    "bilan_experimentation = conduire_experimentation(echantilloner_donnees(cleanning.clean(corpus.obtenir())), definir_experiences())\n",
    "#mongo_db = db_provider.MongoDB('experiences').ajouter_documents(bilan_experimentation)\n",
    "editier_experimentation(resultats_experience_to_panda({}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
